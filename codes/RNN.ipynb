{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN+HRu/x6zT/KnCcymlFF44"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"source":["import numpy as np\n","\n","class SimpleRNN:\n","    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):\n","        self.hidden_size = hidden_size\n","        self.learning_rate = learning_rate\n","\n","        # Weight initialization\n","        self.Wxh = np.random.randn(hidden_size, input_size) * 0.01  # Input to hidden\n","        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01 # Hidden to hidden\n","        self.Why = np.random.randn(output_size, hidden_size) * 0.01 # Hidden to output\n","        self.bh = np.zeros((hidden_size, 1))  # Hidden bias\n","        self.by = np.zeros((output_size, 1))  # Output bias\n","\n","    def forward(self, inputs):\n","        h_prev = np.zeros((self.hidden_size, 1))\n","        hs = {}\n","        ys = {}\n","\n","        for t in range(len(inputs)):\n","            x = np.reshape(inputs[t], (-1, 1))\n","            h_prev = np.tanh(np.dot(self.Wxh, x) + np.dot(self.Whh, h_prev) + self.bh)# activation functions\n","\n","            y = np.dot(self.Why, h_prev) + self.by\n","            hs[t] = h_prev\n","            ys[t] = y\n","\n","        return ys, hs\n","\n","    def backward(self, inputs, targets, hs, ys):\n","        dWxh, dWhh, dWhy = np.zeros_like(self.Wxh), np.zeros_like(self.Whh), np.zeros_like(self.Why)\n","        dbh, dby = np.zeros_like(self.bh), np.zeros_like(self.by)\n","        dh_next = np.zeros((self.hidden_size, 1))\n","\n","        for t in reversed(range(len(inputs))):\n","            dy = np.copy(ys[t])\n","            dy -= targets[t].reshape(-1, 1)\n","\n","            dWhy += np.dot(dy, hs[t].T)\n","            dby += dy\n","\n","            dh = np.dot(self.Why.T, dy) + dh_next\n","            dh_raw = (1 - hs[t] * hs[t]) * dh\n","            dbh += dh_raw\n","            dWxh += np.dot(dh_raw, inputs[t].reshape(1, -1))\n","\n","            # Only update dWhh if t > 0 to avoid KeyError\n","            if t > 0:\n","                dWhh += np.dot(dh_raw, hs[t-1].T)\n","\n","            dh_next = np.dot(self.Whh.T, dh_raw)\n","\n","        for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n","            np.clip(dparam, -1, 1, out=dparam)\n","\n","        self.Wxh -= self.learning_rate * dWxh\n","        self.Whh -= self.learning_rate * dWhh\n","        self.Why -= self.learning_rate * dWhy\n","        self.bh -= self.learning_rate * dbh\n","        self.by -= self.learning_rate * dby\n","\n","    def train(self, inputs, targets, epochs=10):\n","        for epoch in range(epochs):\n","            ys, hs = self.forward(inputs)\n","            self.backward(inputs, targets, hs, ys)\n","            if epoch % 100 == 0:\n","                loss = np.sum((targets - np.array(list(ys.values())).squeeze()) ** 2)\n","                print(f'Epoch {epoch}, Loss: {loss}')\n","    def predict(self, inputs):\n","        ys, _ = self.forward(inputs)\n","        return list(ys.values())[-1]\n","\n","# Example usage\n","inputs = np.array([30, 32, 34, 33, 31, 30, 29])  # Temperature for a week\n","targets = np.array([32, 34, 33, 31, 30, 29, 28])  # Next day temperature\n","\n","rnn = SimpleRNN(input_size=1, hidden_size=10, output_size=1)\n","rnn.train(inputs, targets,epochs=1000)"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P0NvCtYjFJdj","executionInfo":{"status":"ok","timestamp":1719833954699,"user_tz":-330,"elapsed":1260,"user":{"displayName":"Venky","userId":"00375737265949268018"}},"outputId":"2ffeb795-c90d-48c6-b4b4-53199bf15a26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 6756.682259943567\n","Epoch 100, Loss: 2932.8348424316864\n","Epoch 200, Loss: 642.7041246556953\n","Epoch 300, Loss: 27.99982576879568\n","Epoch 400, Loss: 27.99981961081971\n","Epoch 500, Loss: 27.99981299087168\n","Epoch 600, Loss: 27.999805853769356\n","Epoch 700, Loss: 27.999798134992975\n","Epoch 800, Loss: 27.999789758579674\n","Epoch 900, Loss: 27.999780634407628\n"]}]},{"cell_type":"code","source":["test_input = np.array([31, 30, 29, 28, 27, 26, 25])  # Last week\n","prediction = rnn.predict(test_input)\n","print(f'Predicted temperature: {prediction}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bRrFlWIDFjNT","executionInfo":{"status":"ok","timestamp":1719833960303,"user_tz":-330,"elapsed":427,"user":{"displayName":"Venky","userId":"00375737265949268018"}},"outputId":"db438510-cbbb-4ca5-f7a6-f2b55f4bd29a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted temperature: [[30.99970323]]\n"]}]},{"cell_type":"markdown","source":["# Long Short term memory neural networking implementation\n"],"metadata":{"id":"SJex24YFgxOf"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Sample weather data (7 days of temperature data)\n","data = np.array([\n","    [20, 22, 23, 21, 20, 22, 24],  # Week 1\n","    [22, 23, 24, 22, 21, 23, 25],  # Week 2\n","    [21, 22, 23, 22, 21, 22, 24],  # Week 3\n","])\n","\n","# Calculate mean and std for later use\n","data_mean = np.mean(data)\n","data_std = np.std(data)\n","\n","# Normalize the data\n","data_normalized = (data - data_mean) / data_std\n","\n","# Prepare input (X) and target (y) data\n","X = data_normalized[:, :-1]  # First 6 days of each week\n","y = data_normalized[:, -1]   # Last day of each week\n","\n","# Hyperparameters\n","input_size = 1\n","hidden_size = 4\n","output_size = 1\n","learning_rate = 0.01\n","epochs = 2000\n","\n","# Initialize weights\n","Wf = np.random.randn(hidden_size, hidden_size + input_size) * 0.01\n","Wi = np.random.randn(hidden_size, hidden_size + input_size) * 0.01\n","Wc = np.random.randn(hidden_size, hidden_size + input_size) * 0.01\n","Wo = np.random.randn(hidden_size, hidden_size + input_size) * 0.01\n","Wy = np.random.randn(output_size, hidden_size) * 0.01\n","\n","bf = np.zeros((hidden_size, 1))\n","bi = np.zeros((hidden_size, 1))\n","bc = np.zeros((hidden_size, 1))\n","bo = np.zeros((hidden_size, 1))\n","by = np.zeros((output_size, 1))\n","\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def dsigmoid(y):\n","    return y * (1 - y)\n","\n","def tanh(x):\n","    return np.tanh(x)\n","\n","def dtanh(y):\n","    return 1 - y**2\n","\n","def forward_pass(x, h_prev, c_prev):\n","    concat = np.vstack((h_prev, x))\n","\n","    f = sigmoid(np.dot(Wf, concat) + bf)\n","    i = sigmoid(np.dot(Wi, concat) + bi)\n","    c_tilde = tanh(np.dot(Wc, concat) + bc)\n","    o = sigmoid(np.dot(Wo, concat) + bo)\n","\n","    c = f * c_prev + i * c_tilde\n","    h = o * tanh(c)\n","\n","    y = np.dot(Wy, h) + by\n","\n","    cache = (f, i, c_tilde, o, c, h, y, concat, c_prev)\n","    return cache\n","\n","def backward_pass(dy, cache, dc_next, dh_next):\n","    f, i, c_tilde, o, c, h, y, concat, c_prev = cache\n","\n","    dy = dy.reshape(-1, 1)\n","\n","    dh = np.dot(Wy.T, dy) + dh_next\n","    do = dh * tanh(c)\n","    dc = dh * o * dtanh(tanh(c)) + dc_next\n","    dc_tilde = dc * i\n","    di = dc * c_tilde\n","    df = dc * c_prev  # Fixed: use c_prev instead of concat[-hidden_size:]\n","\n","    dWo = np.dot(do * dsigmoid(o), concat.T)\n","    dWi = np.dot(di * dsigmoid(i), concat.T)\n","    dWf = np.dot(df * dsigmoid(f), concat.T)\n","    dWc = np.dot(dc_tilde * dtanh(c_tilde), concat.T)\n","\n","    dWy = np.dot(dy, h.T)\n","    dby = dy\n","\n","    dbo = do * dsigmoid(o)\n","    dbi = di * dsigmoid(i)\n","    dbf = df * dsigmoid(f)\n","    dbc = dc_tilde * dtanh(c_tilde)\n","\n","    dconcat = (np.dot(Wo.T, do * dsigmoid(o)) +\n","               np.dot(Wi.T, di * dsigmoid(i)) +\n","               np.dot(Wf.T, df * dsigmoid(f)) +\n","               np.dot(Wc.T, dc_tilde * dtanh(c_tilde)))\n","\n","    dh_prev = dconcat[:hidden_size]\n","    dc_prev = f * dc\n","\n","    return dWf, dWi, dWc, dWo, dWy, dbf, dbi, dbc, dbo, dby, dh_prev, dc_prev\n","\n","# Training loop\n","for epoch in range(epochs):\n","    # Shuffle the data\n","    indices = np.arange(len(X))\n","    np.random.shuffle(indices)\n","    X_shuffled = X[indices]\n","    y_shuffled = y[indices]\n","\n","    loss = 0\n","    for j in range(len(X_shuffled)):\n","        x = X_shuffled[j].reshape(-1, 1)\n","        target = y_shuffled[j]\n","\n","        h = np.zeros((hidden_size, 1))\n","        c = np.zeros((hidden_size, 1))\n","\n","        caches = []\n","        for t in range(6):  # 6 time steps (6 days)\n","            cache = forward_pass(x[t:t+1], h, c)\n","            caches.append(cache)\n","            _, _, _, _, c, h, _, _, _ = cache\n","\n","        y_pred = caches[-1][6]\n","        loss += (y_pred - target)**2 / 2\n","\n","        dy = y_pred - target\n","        dh_next = np.zeros_like(h)\n","        dc_next = np.zeros_like(c)\n","\n","        dWf, dWi, dWc, dWo, dWy = np.zeros_like(Wf), np.zeros_like(Wi), np.zeros_like(Wc), np.zeros_like(Wo), np.zeros_like(Wy)\n","        dbf, dbi, dbc, dbo, dby = np.zeros_like(bf), np.zeros_like(bi), np.zeros_like(bc), np.zeros_like(bo), np.zeros_like(by)\n","\n","        for t in reversed(range(6)):\n","            grad = backward_pass(dy, caches[t], dc_next, dh_next)\n","            dWf_, dWi_, dWc_, dWo_, dWy_, dbf_, dbi_, dbc_, dbo_, dby_, dh_next, dc_next = grad\n","\n","            dWf += dWf_\n","            dWi += dWi_\n","            dWc += dWc_\n","            dWo += dWo_\n","            dWy += dWy_\n","            dbf += dbf_\n","            dbi += dbi_\n","            dbc += dbc_\n","            dbo += dbo_\n","            dby += dby_\n","\n","        # Update weights with learning rate decay\n","        lr = learning_rate / (1 + epoch / 1000)  # Simple learning rate decay\n","        Wf -= lr * dWf\n","        Wi -= lr * dWi\n","        Wc -= lr * dWc\n","        Wo -= lr * dWo\n","        Wy -= lr * dWy\n","        bf -= lr * dbf\n","        bi -= lr * dbi\n","        bc -= lr * dbc\n","        bo -= lr * dbo\n","        by -= lr * dby\n","\n","    if epoch % 100 == 0:\n","        print(f\"Epoch {epoch}, Loss: {loss/len(X)}\")\n","\n","# Test the model\n","test_week = np.array([21, 23, 22, 20, 22, 23]).reshape(1, -1)\n","test_week_normalized = (test_week - data_mean) / data_std  # Normalize using training data statistics\n","\n","h = np.zeros((hidden_size, 1))\n","c = np.zeros((hidden_size, 1))\n","\n","for t in range(6):\n","    x = test_week_normalized[0, t].reshape(-1, 1)\n","    cache = forward_pass(x, h, c)\n","    _, _, _, _, c, h, _, _, _ = cache\n","\n","y_pred = cache[6]\n","predicted_temp = y_pred * data_std + data_mean  # Denormalize using training data statistics\n","print(f\"Predicted temperature for the 7th day: {predicted_temp[0, 0]:.2f}°C\")\n","\n","# Print actual temperatures for comparison\n","print(f\"Actual temperatures: {data[:, -1]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kCmzlaZ6pUyU","executionInfo":{"status":"ok","timestamp":1719927152616,"user_tz":-330,"elapsed":6470,"user":{"displayName":"Venky","userId":"00375737265949268018"}},"outputId":"d6af0885-831b-4d64-b814-5f1b31668fd3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: [[1.21044865]]\n","Epoch 100, Loss: [[0.06871926]]\n","Epoch 200, Loss: [[0.06832451]]\n","Epoch 300, Loss: [[0.06767133]]\n","Epoch 400, Loss: [[0.06602391]]\n","Epoch 500, Loss: [[0.06164647]]\n","Epoch 600, Loss: [[0.0523063]]\n","Epoch 700, Loss: [[0.03777212]]\n","Epoch 800, Loss: [[0.02229797]]\n","Epoch 900, Loss: [[0.01156307]]\n","Epoch 1000, Loss: [[0.00653585]]\n","Epoch 1100, Loss: [[0.0044739]]\n","Epoch 1200, Loss: [[0.00345836]]\n","Epoch 1300, Loss: [[0.00282572]]\n","Epoch 1400, Loss: [[0.00238426]]\n","Epoch 1500, Loss: [[0.0020593]]\n","Epoch 1600, Loss: [[0.00180792]]\n","Epoch 1700, Loss: [[0.00160362]]\n","Epoch 1800, Loss: [[0.00143845]]\n","Epoch 1900, Loss: [[0.00130179]]\n","Predicted temperature for the 7th day: 24.59°C\n","Actual temperatures: [24 25 24]\n"]}]},{"cell_type":"code","source":["y_pred = cache[20]\n","predicted_temp = y_pred * np.std(data) + np.mean(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158},"id":"zzp6cFU0byKU","executionInfo":{"status":"error","timestamp":1719906813879,"user_tz":-330,"elapsed":651,"user":{"displayName":"Venky","userId":"00375737265949268018"}},"outputId":"b6109ea2-dd11-4fb7-b1d5-0f05ec45ef76"},"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"tuple index out of range","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-fe33857b2033>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredicted_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: tuple index out of range"]}]},{"source":["def predict_next_day(past_6_days, model_data):\n","    # Normalize the input data\n","    normalized_input = (past_6_days - np.mean(model_data)) / np.std(model_data)\n","\n","    h = np.zeros((hidden_size, 1))\n","    c = np.zeros((hidden_size, 1))\n","\n","    for t in range(6):\n","        x = normalized_input[t].reshape(-1, 1)\n","        cache = forward_pass(x, h, c)\n","        _, _, _, _, c, h, _, _, _ = cache # Unpack all 9 values returned by forward_pass\n","\n","    y_pred = cache[6]\n","    predicted_temp = y_pred * np.std(model_data) + np.mean(model_data)\n","    return predicted_temp[0, 0]"],"cell_type":"code","metadata":{"id":"elcysJBym502"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def temperature_prediction_interface():\n","    print(\"Enter the temperatures for the past 6 days:\")\n","    past_6_days = []\n","    for i in range(6):\n","        temp = float(input(f\"Day {i+1} temperature: \"))\n","        past_6_days.append(temp)\n","\n","    next_day_temp = predict_next_day(np.array(past_6_days))\n","    print(f\"Predicted temperature for tomorrow: {next_day_temp:.2f}°C\")\n","\n","# Run the interface\n","temperature_prediction_interface()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"9GLWjVlBnYiU","executionInfo":{"status":"error","timestamp":1719926653064,"user_tz":-330,"elapsed":25177,"user":{"displayName":"Venky","userId":"00375737265949268018"}},"outputId":"4ae77591-6d72-4ceb-9e36-ee123fcb82a6"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter the temperatures for the past 6 days:\n","Day 1 temperature: 40\n","Day 2 temperature: 39\n","Day 3 temperature: 38\n","Day 4 temperature: 41\n","Day 5 temperature: 40\n","Day 6 temperature: 39\n"]},{"output_type":"error","ename":"TypeError","evalue":"predict_next_day() missing 1 required positional argument: 'model_data'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-70d18a70c907>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Run the interface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtemperature_prediction_interface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-70d18a70c907>\u001b[0m in \u001b[0;36mtemperature_prediction_interface\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mpast_6_days\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mnext_day_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_next_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_6_days\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicted temperature for tomorrow: {next_day_temp:.2f}°C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: predict_next_day() missing 1 required positional argument: 'model_data'"]}]},{"source":["def temperature_prediction_interface():\n","    print(\"Enter the temperatures for the past 6 days:\")\n","    past_6_days = []\n","    for i in range(6):\n","        temp = float(input(f\"Day {i+1} temperature: \"))\n","        past_6_days.append(temp)\n","\n","    # Pass the original data to the prediction function\n","    next_day_temp = predict_next_day(np.array(past_6_days), data)  # 'data' is the original temperature data\n","    print(f\"Predicted temperature for tomorrow: {next_day_temp:.2f}°C\")\n","\n","# Run the interface\n","temperature_prediction_interface()"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BtWA0is9nsyP","executionInfo":{"status":"ok","timestamp":1719927218186,"user_tz":-330,"elapsed":25859,"user":{"displayName":"Venky","userId":"00375737265949268018"}},"outputId":"5db3c2a2-6a7e-47f4-f4b8-a17edab49c6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the temperatures for the past 6 days:\n","Day 1 temperature: 25\n","Day 2 temperature: 24\n","Day 3 temperature: 27\n","Day 4 temperature: 26\n","Day 5 temperature: 22\n","Day 6 temperature: 26\n","Predicted temperature for tomorrow: 26.38°C\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","class RNN:\n","    def __init__(self, input_size, hidden_size, output_size):\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","\n","        # Initialize weights\n","        self.Wxh = np.random.randn(hidden_size, input_size) * 0.01\n","        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n","        self.Why = np.random.randn(output_size, hidden_size) * 0.01\n","\n","        # Initialize biases\n","        self.bh = np.zeros((hidden_size, 1))\n","        self.by = np.zeros((output_size, 1))\n","\n","    def forward(self, inputs):\n","        h = np.zeros((self.hidden_size, 1))\n","        self.last_inputs = inputs\n","        self.last_hs = { 0: h }\n","\n","        # Forward pass\n","        for t, x in enumerate(inputs):\n","            h = np.tanh(np.dot(self.Wxh, x) + np.dot(self.Whh, h) + self.bh)\n","            self.last_hs[t+1] = h\n","\n","        # Compute output\n","        y = np.dot(self.Why, h) + self.by\n","        p = np.exp(y) / np.sum(np.exp(y))\n","\n","        return p, h\n","\n","    def backward(self, d_y, learn_rate=2e-3):\n","        n = len(self.last_inputs)\n","\n","        # Backprop into Why and by\n","        d_Why = np.dot(d_y, self.last_hs[n].T)\n","        d_by = d_y\n","\n","        # Backprop into Whh, Wxh, and bh\n","        d_h = np.dot(self.Why.T, d_y)\n","        d_Whh = np.zeros_like(self.Whh)\n","        d_Wxh = np.zeros_like(self.Wxh)\n","        d_bh = np.zeros_like(self.bh)  # Make sure d_bh has the correct shape\n","\n","        for t in reversed(range(n)):\n","            temp = (1 - self.last_hs[t+1] ** 2) * d_h\n","            d_bh += temp  # Now the shapes should match\n","            d_Whh += np.dot(temp, self.last_hs[t].T)\n","            d_Wxh += np.dot(temp, self.last_inputs[t].T)\n","            d_h = np.dot(self.Whh.T, temp)\n","\n","\n","\n","\n","        # Clip to prevent exploding gradients\n","        for d in [d_Wxh, d_Whh, d_Why, d_bh, d_by]:\n","            np.clip(d, -5, 5, out=d)\n","\n","        # Update weights and biases\n","        self.Wxh -= learn_rate * d_Wxh\n","        self.Whh -= learn_rate * d_Whh\n","        self.Why -= learn_rate * d_Why\n","        self.bh -= learn_rate * d_bh\n","        self.by -= learn_rate * d_by\n","\n","def predict_next_word(rnn, input_sequence, vocab):\n","    input_vector = [np.eye(len(vocab))[vocab[word]] for word in input_sequence]\n","    p, _ = rnn.forward(input_vector)\n","    next_word_index = np.argmax(p)\n","\n","    # Convert the predicted index to a word\n","    vocab_list = list(vocab.keys())\n","    if 0 <= next_word_index < len(vocab_list):\n","        return vocab_list[next_word_index]\n","    else:\n","        return \"Unknown\"\n","\n","def train_rnn(rnn, vocab, sentences, epochs=100):\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for sentence in sentences:\n","            inputs = [np.eye(len(vocab))[vocab[word]] for word in sentence[:-1]]\n","            target = np.zeros((len(vocab), 1))\n","            target[vocab[sentence[-1]]] = 1\n","\n","            # Forward pass\n","            p, _ = rnn.forward(inputs)\n","\n","            # Compute loss\n","            loss = -np.sum(target * np.log(p))\n","            total_loss += loss\n","\n","            # Backward pass\n","            d_y = p - target\n","            rnn.backward(d_y)\n","\n","        if epoch % 10 == 0:\n","            print(f\"Epoch {epoch}, Loss: {total_loss / len(sentences)}\")\n","\n","# Example usage\n","vocab = {'hello': 0, 'world': 1, 'how': 2, 'are': 3, 'you': 4}\n","input_size = len(vocab)\n","hidden_size = 100\n","output_size = len(vocab)\n","\n","rnn = RNN(input_size, hidden_size, output_size)\n","\n","# Training data\n","sentences = [\n","    ['hello', 'how', 'are', 'you'],\n","    ['hello', 'world', 'how', 'are'],\n","    ['how', 'are', 'you', 'world']\n","]\n","\n","# Train the RNN\n","train_rnn(rnn, vocab, sentences, epochs=100)\n","\n","# Test the trained RNN\n","input_sequence = ['hello', 'how', 'are']\n","next_word = predict_next_word(rnn, input_sequence, vocab)\n","print(f\"Predicted next word: {next_word}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"EIxoF2nPm7o2","executionInfo":{"status":"error","timestamp":1720010697470,"user_tz":-330,"elapsed":559,"user":{"displayName":"Venky","userId":"00375737265949268018"}},"outputId":"08273c68-9732-401d-f607-b4f48bb68a6a"},"execution_count":13,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"non-broadcastable output operand with shape (100,1) doesn't match the broadcast shape (100,100)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-a016efda3a35>\u001b[0m in \u001b[0;36m<cell line: 118>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m# Train the RNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0mtrain_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# Test the trained RNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-a016efda3a35>\u001b[0m in \u001b[0;36mtrain_rnn\u001b[0;34m(rnn, vocab, sentences, epochs)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0md_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-a016efda3a35>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, d_y, learn_rate)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0md_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0md_bh\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtemp\u001b[0m  \u001b[0;31m# Now the shapes should match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0md_Whh\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0md_Wxh\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (100,1) doesn't match the broadcast shape (100,100)"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","class RNN:\n","    def __init__(self, input_size, hidden_size, output_size):\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","\n","        # Initialize weights\n","        self.Wxh = np.random.randn(hidden_size, input_size) * 0.01\n","        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n","        self.Why = np.random.randn(output_size, hidden_size) * 0.01\n","\n","        # Initialize biases\n","        self.bh = np.zeros((hidden_size, 1))\n","        self.by = np.zeros((output_size, 1))\n","\n","    def forward(self, inputs):\n","        h = np.zeros((self.hidden_size, 1))\n","        self.last_inputs = inputs\n","        self.last_hs = { 0: h }\n","\n","        # Forward pass\n","        for t, x in enumerate(inputs):\n","            h = np.tanh(np.dot(self.Wxh, x.reshape(-1, 1)) + np.dot(self.Whh, h) + self.bh)\n","            self.last_hs[t+1] = h\n","\n","        # Compute output\n","        y = np.dot(self.Why, h) + self.by\n","        p = np.exp(y) / np.sum(np.exp(y))\n","\n","        return p, h\n","\n","    def backward(self, d_y, learn_rate=2e-3):\n","        n = len(self.last_inputs)\n","\n","        # Backprop into Why and by\n","        d_Why = np.dot(d_y, self.last_hs[n].T)\n","        d_by = d_y\n","\n","        # Backprop into Whh, Wxh, and bh\n","        d_h = np.dot(self.Why.T, d_y)\n","        d_Whh = np.zeros_like(self.Whh)\n","        d_Wxh = np.zeros_like(self.Wxh)\n","        d_bh = np.zeros_like(self.bh)\n","\n","        for t in reversed(range(n)):\n","            temp = (1 - self.last_hs[t+1] ** 2) * d_h\n","            d_bh += temp\n","            d_Whh += np.dot(temp, self.last_hs[t].T)\n","            d_Wxh += np.dot(temp, self.last_inputs[t].reshape(1, -1))\n","            d_h = np.dot(self.Whh.T, temp)\n","\n","        # Clip to prevent exploding gradients\n","        for d in [d_Wxh, d_Whh, d_Why, d_bh, d_by]:\n","            np.clip(d, -5, 5, out=d)\n","\n","        # Update weights and biases\n","        self.Wxh -= learn_rate * d_Wxh\n","        self.Whh -= learn_rate * d_Whh\n","        self.Why -= learn_rate * d_Why\n","        self.bh -= learn_rate * d_bh\n","        self.by -= learn_rate * d_by\n","\n","def predict_next_word(rnn, input_sequence, vocab):\n","    input_vector = [np.eye(len(vocab))[vocab[word]] for word in input_sequence]\n","    p, _ = rnn.forward(input_vector)\n","    next_word_index = np.argmax(p)\n","\n","    # Convert the predicted index to a word\n","    vocab_list = list(vocab.keys())\n","    if 0 <= next_word_index < len(vocab_list):\n","        return vocab_list[next_word_index]\n","    else:\n","        return \"Unknown\"\n","\n","def train_rnn(rnn, vocab, sentences, epochs=100):\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for sentence in sentences:\n","            inputs = [np.eye(len(vocab))[vocab[word]] for word in sentence[:-1]]\n","            target = np.zeros((len(vocab), 1))\n","            target[vocab[sentence[-1]]] = 1\n","\n","            # Forward pass\n","            p, _ = rnn.forward(inputs)\n","\n","            # Compute loss\n","            loss = -np.sum(target * np.log(p + 1e-8))  # Added small epsilon to avoid log(0)\n","            total_loss += loss\n","\n","            # Backward pass\n","            d_y = p - target\n","            rnn.backward(d_y)\n","\n","        if epoch % 10 == 0:\n","            print(f\"Epoch {epoch}, Loss: {total_loss / len(sentences)}\")\n","\n","# Example usage\n","vocab = {'hello': 0, 'world': 1, 'how': 2, 'are': 3, 'you': 4}\n","input_size = len(vocab)\n","hidden_size = 100\n","output_size = len(vocab)\n","\n","rnn = RNN(input_size, hidden_size, output_size)\n","\n","# Training data\n","sentences = [\n","    ['hello', 'how', 'are', 'you'],\n","    ['hello', 'world', 'how', 'are'],\n","    ['how', 'are', 'you', 'world']\n","]\n","\n","# Train the RNN\n","train_rnn(rnn, vocab, sentences, epochs=100)\n","\n","# Test the trained RNN\n","input_sequence = ['hello', 'how', 'are']\n","next_word = predict_next_word(rnn, input_sequence, vocab)\n","print(f\"Predicted next word: {next_word}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-84TEOMUpU3Y","executionInfo":{"status":"ok","timestamp":1720011028325,"user_tz":-330,"elapsed":521,"user":{"displayName":"Venky","userId":"00375737265949268018"}},"outputId":"236a8de5-c376-4838-c897-c23e2e11f73d"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 1.608919099085386\n","Epoch 10, Loss: 1.6006489095838894\n","Epoch 20, Loss: 1.5925687247242786\n","Epoch 30, Loss: 1.5846725006284839\n","Epoch 40, Loss: 1.5769543694186414\n","Epoch 50, Loss: 1.56940863277602\n","Epoch 60, Loss: 1.5620297557105907\n","Epoch 70, Loss: 1.5548123605228046\n","Epoch 80, Loss: 1.5477512209417288\n","Epoch 90, Loss: 1.5408412564259188\n","Predicted next word: you\n"]}]},{"cell_type":"code","source":["input_sequence = ['hello', 'how', 'world']\n","next_word = predict_next_word(rnn, input_sequence, vocab)\n","print(f\"Predicted next word: {next_word}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ETZh8Yo8pbkz","executionInfo":{"status":"ok","timestamp":1720011126739,"user_tz":-330,"elapsed":532,"user":{"displayName":"Venky","userId":"00375737265949268018"}},"outputId":"fc81f619-9bda-4ee8-c73e-f1b28c9b611a"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted next word: are\n"]}]},{"cell_type":"markdown","source":["# RNN for large textual data to predict next  word sequnece"],"metadata":{"id":"5c1ifk9Hqn7w"}},{"cell_type":"code","source":["import numpy as np\n","import re\n","from collections import defaultdict\n","\n","class RNN:\n","    def __init__(self, vocab_size, hidden_size):\n","        self.vocab_size = vocab_size\n","        self.hidden_size = hidden_size\n","\n","        # Initialize weights\n","        self.Wxh = np.random.randn(hidden_size, vocab_size) * 0.01\n","        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n","        self.Why = np.random.randn(vocab_size, hidden_size) * 0.01\n","\n","        # Initialize biases\n","        self.bh = np.zeros((hidden_size, 1))\n","        self.by = np.zeros((vocab_size, 1))\n","\n","    def forward(self, inputs):\n","        h = np.zeros((self.hidden_size, 1))\n","        self.last_inputs = inputs\n","        self.last_hs = { 0: h }\n","\n","        # Forward pass\n","        for t, x in enumerate(inputs):\n","            h = np.tanh(np.dot(self.Wxh, x.reshape(-1, 1)) + np.dot(self.Whh, h) + self.bh)\n","            self.last_hs[t+1] = h\n","\n","        # Compute output\n","        y = np.dot(self.Why, h) + self.by\n","        p = np.exp(y) / np.sum(np.exp(y))\n","\n","        return p, h\n","\n","    def backward(self, d_y, learn_rate=1e-3):\n","        n = len(self.last_inputs)\n","\n","        # Backprop into Why and by\n","        d_Why = np.dot(d_y, self.last_hs[n].T)\n","        d_by = d_y\n","\n","        # Backprop into Whh, Wxh, and bh\n","        d_h = np.dot(self.Why.T, d_y)\n","        d_Whh = np.zeros_like(self.Whh)\n","        d_Wxh = np.zeros_like(self.Wxh)\n","        d_bh = np.zeros_like(self.bh)\n","\n","        for t in reversed(range(n)):\n","            temp = (1 - self.last_hs[t+1] ** 2) * d_h\n","            d_bh += temp\n","            d_Whh += np.dot(temp, self.last_hs[t].T)\n","            d_Wxh += np.dot(temp, self.last_inputs[t].reshape(1, -1))\n","            d_h = np.dot(self.Whh.T, temp)\n","\n","        # Clip to prevent exploding gradients\n","        for d in [d_Wxh, d_Whh, d_Why, d_bh, d_by]:\n","            np.clip(d, -5, 5, out=d)\n","\n","        # Update weights and biases\n","        self.Wxh -= learn_rate * d_Wxh\n","        self.Whh -= learn_rate * d_Whh\n","        self.Why -= learn_rate * d_Why\n","        self.bh -= learn_rate * d_bh\n","        self.by -= learn_rate * d_by\n","\n","def preprocess_text(text):\n","    # Convert to lowercase and remove special characters\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n","    words = text.split()\n","    return words\n","\n","def build_vocab(words):\n","    vocab = defaultdict(lambda: len(vocab))\n","    vocab['<unk>'] = 0  # Unknown token\n","    for word in words:\n","        vocab[word]\n","    return dict(vocab)\n","\n","def encode_text(text, vocab):\n","    return [vocab[word] if word in vocab else vocab['<unk>'] for word in text]\n","\n","def one_hot_encode(indices, vocab_size):\n","    return [np.eye(vocab_size)[i] for i in indices]\n","\n","def train_rnn(rnn, vocab, text, seq_length, epochs=100, learn_rate=1e-3):\n","    encoded_text = encode_text(text, vocab)\n","    vocab_size = len(vocab)\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for i in range(0, len(encoded_text) - seq_length, seq_length):\n","            inputs = one_hot_encode(encoded_text[i:i+seq_length], vocab_size)\n","            targets = encoded_text[i+1:i+seq_length+1]\n","\n","            # Forward pass\n","            p, _ = rnn.forward(inputs)\n","\n","            # Compute loss\n","            loss = -np.sum([np.log(p[t, targets[t]]) for t in range(seq_length)])\n","            total_loss += loss\n","\n","            # Backward pass\n","            d_y = p.copy()\n","            for t in range(seq_length):\n","                d_y[targets[t], t] -= 1\n","            rnn.backward(d_y, learn_rate)\n","\n","        if epoch % 10 == 0:\n","            print(f\"Epoch {epoch}, Loss: {total_loss / (len(encoded_text) // seq_length)}\")\n","\n","def generate_text(rnn, vocab, seed_text, n_generate=100):\n","    inv_vocab = {v: k for k, v in vocab.items()}\n","    encoded_seed = encode_text(seed_text.split(), vocab)\n","    current_sequence = one_hot_encode(encoded_seed, len(vocab))\n","    generated_text = seed_text.split()\n","\n","    for _ in range(n_generate):\n","        p, _ = rnn.forward(current_sequence)\n","        next_word_idx = np.random.choice(len(vocab), p=p.ravel())\n","        generated_text.append(inv_vocab[next_word_idx])\n","        current_sequence = current_sequence[1:] + [np.eye(len(vocab))[next_word_idx]]\n","\n","    return ' '.join(generated_text)\n","\n","# Example usage\n","text = \"\"\"\n","The sun rose slowly over the misty hills, painting the sky in hues of pink and gold. Birds chirped their morning songs, welcoming the new day with melodious tunes. In the nearby village, people began to stir, ready to face whatever challenges lay ahead.\n","\n","Sarah, a young artist, woke early and made her way to her favorite spot by the lake. She set up her easel and began to capture the serene landscape on canvas. The gentle lapping of water against the shore provided a soothing rhythm as she worked.\n","\n","Meanwhile, in the bustling city miles away, Mark hurried through crowded streets, briefcase in hand. He weaved through the sea of commuters, all racing against time. The aroma of fresh coffee wafted from nearby cafes, tempting many to pause their rush for a moment of indulgence.\n","\n","In a quiet library, an elderly man named George pored over ancient texts. His wrinkled hands carefully turned fragile pages, each one a window to forgotten worlds. The musty smell of old books filled the air, a scent he had grown to love over decades of study.\n","\n","As noon approached, children laughed and played in the local park. Their joyful shouts echoed across the green expanse, a stark contrast to the somber atmosphere of the nearby courthouse. There, Laura, a dedicated lawyer, presented her case with passion and conviction, fighting for justice in a world often devoid of it.\n","\n","As evening fell, families gathered around dinner tables, sharing stories of their day. The clinking of cutlery and warm conversations filled homes with a sense of togetherness. Outside, street lamps flickered to life, casting a soft glow over the quiet neighborhoods.\n","\n","In a cozy bookshop at the corner of Main Street, Emma arranged a display of new arrivals. She loved introducing readers to new worlds and ideas, each book a portal to adventure or knowledge. The bell above the door chimed as customers wandered in, drawn by the promise of literary treasures.\n","\n","As night descended, the city transformed. Neon lights buzzed to life, painting the streets in vibrant colors. Music drifted from bars and clubs, where people danced away their worries. In contrast, the countryside lay peaceful under a blanket of stars, crickets providing a gentle nocturnal symphony.\n","\n","And so the world turned, each moment a story, each person a character in the grand narrative of life. From the highest mountains to the deepest oceans, countless tales unfolded, waiting to be told, heard, and remembered.\n","\"\"\"\n","\n","# Preprocess the text\n","words = preprocess_text(text)\n","vocab = build_vocab(words)\n","rnn = RNN(len(vocab), hidden_size=100)\n","\n","# Train the RNN\n","train_rnn(rnn, vocab, words, seq_length=5, epochs=100, learn_rate=1e-3)\n","\n","# Generate text\n","seed_text = \"The sun rose\"\n","generated_text = generate_text(rnn, vocab, seed_text, n_generate=20)\n","print(f\"Generated text: {generated_text}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"MW6BsWN7qm5c","executionInfo":{"status":"error","timestamp":1720012528005,"user_tz":-330,"elapsed":624,"user":{"displayName":"Venky","userId":"00375737265949268018"}},"outputId":"2680cf00-7e8a-45ff-edb1-ed3cf256e24e"},"execution_count":22,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"index 2 is out of bounds for axis 1 with size 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-075617e30d96>\u001b[0m in \u001b[0;36m<cell line: 152>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;31m# Train the RNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m \u001b[0mtrain_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;31m# Generate text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-075617e30d96>\u001b[0m in \u001b[0;36mtrain_rnn\u001b[0;34m(rnn, vocab, text, seq_length, epochs, learn_rate)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-075617e30d96>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 1"]}]},{"cell_type":"code","source":["import numpy as np\n","import re\n","from collections import defaultdict\n","\n","class RNN:\n","    def __init__(self, vocab_size, hidden_size):\n","        self.vocab_size = vocab_size\n","        self.hidden_size = hidden_size\n","\n","        # Initialize weights\n","        self.Wxh = np.random.randn(hidden_size, vocab_size) * 0.01\n","        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n","        self.Why = np.random.randn(vocab_size, hidden_size) * 0.01\n","\n","        # Initialize biases\n","        self.bh = np.zeros((hidden_size, 1))\n","        self.by = np.zeros((vocab_size, 1))\n","\n","    def forward(self, inputs):\n","        h = np.zeros((self.hidden_size, 1))\n","        self.last_inputs = inputs\n","        self.last_hs = { 0: h }\n","\n","        # Forward pass\n","        for t, x in enumerate(inputs):\n","            h = np.tanh(np.dot(self.Wxh, x.reshape(-1, 1)) + np.dot(self.Whh, h) + self.bh)\n","            self.last_hs[t+1] = h\n","\n","        # Compute output\n","        y = np.dot(self.Why, h) + self.by\n","        p = np.exp(y) / np.sum(np.exp(y))\n","\n","        return p, h\n","\n","    def backward(self, d_y, learn_rate=1e-3):\n","        n = len(self.last_inputs)\n","\n","        # Backprop into Why and by\n","        d_Why = np.dot(d_y, self.last_hs[n].T)\n","        d_by = d_y\n","\n","        # Backprop into Whh, Wxh, and bh\n","        d_h = np.dot(self.Why.T, d_y)\n","        d_Whh = np.zeros_like(self.Whh)\n","        d_Wxh = np.zeros_like(self.Wxh)\n","        d_bh = np.zeros_like(self.bh)\n","\n","        for t in reversed(range(n)):\n","            temp = (1 - self.last_hs[t+1] ** 2) * d_h\n","            d_bh += temp\n","            d_Whh += np.dot(temp, self.last_hs[t].T)\n","            d_Wxh += np.dot(temp, self.last_inputs[t].reshape(1, -1))\n","            d_h = np.dot(self.Whh.T, temp)\n","\n","        # Clip to prevent exploding gradients\n","        for d in [d_Wxh, d_Whh, d_Why, d_bh, d_by]:\n","            np.clip(d, -5, 5, out=d)\n","\n","        # Update weights and biases\n","        self.Wxh -= learn_rate * d_Wxh\n","        self.Whh -= learn_rate * d_Whh\n","        self.Why -= learn_rate * d_Why\n","        self.bh -= learn_rate * d_bh\n","        self.by -= learn_rate * d_by\n","\n","def preprocess_text(text):\n","    # Convert to lowercase and remove special characters\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n","    words = text.split()\n","    return words\n","\n","def build_vocab(words):\n","    vocab = defaultdict(lambda: len(vocab))\n","    vocab['<unk>'] = 0  # Unknown token\n","    for word in words:\n","        vocab[word]\n","    return dict(vocab)\n","\n","def encode_text(text, vocab):\n","    return [vocab[word] if word in vocab else vocab['<unk>'] for word in text]\n","\n","def one_hot_encode(indices, vocab_size):\n","    return [np.eye(vocab_size)[i] for i in indices]\n","\n","def train_rnn(rnn, vocab, text, seq_length, epochs=100, learn_rate=1e-3):\n","    encoded_text = encode_text(text, vocab)\n","    vocab_size = len(vocab)\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for i in range(0, len(encoded_text) - seq_length, seq_length):\n","            inputs = one_hot_encode(encoded_text[i:i+seq_length], vocab_size)\n","            targets = encoded_text[i+1:i+seq_length+1]\n","\n","            loss = 0\n","            h = np.zeros((rnn.hidden_size, 1))\n","\n","            # Forward pass\n","            for t in range(seq_length):\n","                p, h = rnn.forward([inputs[t]])\n","                loss += -np.log(p[targets[t], 0])\n","\n","            total_loss += loss\n","\n","            # Backward pass\n","            d_y = p.copy()\n","            d_y[targets[-1]] -= 1\n","            rnn.backward(d_y, learn_rate)\n","\n","        if epoch % 10 == 0:\n","            print(f\"Epoch {epoch}, Loss: {total_loss / (len(encoded_text) // seq_length)}\")\n","\n","def generate_text(rnn, vocab, seed_text, n_generate=100):\n","    inv_vocab = {v: k for k, v in vocab.items()}\n","    encoded_seed = encode_text(seed_text.split(), vocab)\n","    current_sequence = one_hot_encode(encoded_seed, len(vocab))\n","    generated_text = seed_text.split()\n","\n","    h = np.zeros((rnn.hidden_size, 1))\n","    for _ in range(n_generate):\n","        p, h = rnn.forward([current_sequence[-1]])\n","        next_word_idx = np.random.choice(len(vocab), p=p.ravel())\n","        generated_text.append(inv_vocab[next_word_idx])\n","        current_sequence = current_sequence[1:] + [np.eye(len(vocab))[next_word_idx]]\n","\n","    return ' '.join(generated_text)\n","\n","# Example usage\n","text = \"\"\"\n","The sun rose slowly over the misty hills, painting the sky in hues of pink and gold. Birds chirped their morning songs, welcoming the new day with melodious tunes. In the nearby village, people began to stir, ready to face whatever challenges lay ahead.\n","\n","Sarah, a young artist, woke early and made her way to her favorite spot by the lake. She set up her easel and began to capture the serene landscape on canvas. The gentle lapping of water against the shore provided a soothing rhythm as she worked.\n","\n","Meanwhile, in the bustling city miles away, Mark hurried through crowded streets, briefcase in hand. He weaved through the sea of commuters, all racing against time. The aroma of fresh coffee wafted from nearby cafes, tempting many to pause their rush for a moment of indulgence.\n","\n","In a quiet library, an elderly man named George pored over ancient texts. His wrinkled hands carefully turned fragile pages, each one a window to forgotten worlds. The musty smell of old books filled the air, a scent he had grown to love over decades of study.\n","\n","As noon approached, children laughed and played in the local park. Their joyful shouts echoed across the green expanse, a stark contrast to the somber atmosphere of the nearby courthouse. There, Laura, a dedicated lawyer, presented her case with passion and conviction, fighting for justice in a world often devoid of it.\n","\n","As evening fell, families gathered around dinner tables, sharing stories of their day. The clinking of cutlery and warm conversations filled homes with a sense of togetherness. Outside, street lamps flickered to life, casting a soft glow over the quiet neighborhoods.\n","\n","In a cozy bookshop at the corner of Main Street, Emma arranged a display of new arrivals. She loved introducing readers to new worlds and ideas, each book a portal to adventure or knowledge. The bell above the door chimed as customers wandered in, drawn by the promise of literary treasures.\n","\n","As night descended, the city transformed. Neon lights buzzed to life, painting the streets in vibrant colors. Music drifted from bars and clubs, where people danced away their worries. In contrast, the countryside lay peaceful under a blanket of stars, crickets providing a gentle nocturnal symphony.\n","\n","And so the world turned, each moment a story, each person a character in the grand narrative of life. From the highest mountains to the deepest oceans, countless tales unfolded, waiting to be told, heard, and remembered.\n","\"\"\"\n","\n","# Preprocess the text\n","words = preprocess_text(text)\n","vocab = build_vocab(words)\n","rnn = RNN(len(vocab), hidden_size=100)\n","\n","# Train the RNN\n","train_rnn(rnn, vocab, words, seq_length=5, epochs=100, learn_rate=1e-3)\n","\n","# Generate text\n","seed_text = \"The sun rose\"\n","generated_text = generate_text(rnn, vocab, seed_text, n_generate=20)\n","print(f\"Generated text: {generated_text}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LeY-b6p4veQk","executionInfo":{"status":"ok","timestamp":1720012649674,"user_tz":-330,"elapsed":14974,"user":{"displayName":"Venky","userId":"00375737265949268018"}},"outputId":"f7056608-e0ea-4023-bd07-1c696e47246e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 27.537057032677655\n","Epoch 10, Loss: 27.479247470914963\n","Epoch 20, Loss: 27.421969269105535\n","Epoch 30, Loss: 27.365211191709772\n","Epoch 40, Loss: 27.30896033607901\n","Epoch 50, Loss: 27.253199339220355\n","Epoch 60, Loss: 27.197903394948863\n","Epoch 70, Loss: 27.143036953069767\n","Epoch 80, Loss: 27.08854999512541\n","Epoch 90, Loss: 27.03437381461592\n","Generated text: The sun rose or racing wrinkled bars on sense character cutlery shore quiet man study moment conversations soft elderly waiting whatever street over\n"]}]},{"cell_type":"code","source":["seed_text = \"we\"\n","generated_text = generate_text(rnn, vocab, seed_text, n_generate=20)\n","print(f\"Generated text: {generated_text}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7VNaN-5NvnfD","executionInfo":{"status":"ok","timestamp":1720012710943,"user_tz":-330,"elapsed":548,"user":{"displayName":"Venky","userId":"00375737265949268018"}},"outputId":"b1378b76-ee4a-4ad3-aeb5-700d29e2d71c"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated text: we to many courthouse introducing the transformed songs often customers there elderly casting drawn character outside lake made decades birds lapping\n"]}]}]}